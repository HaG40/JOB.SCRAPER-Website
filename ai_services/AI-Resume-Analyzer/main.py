# main.py
# uvicorn main:app --reload --port 5000

from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from groq import Groq
from dotenv import load_dotenv
from PIL import Image
from pdf2image import convert_from_bytes
import pytesseract
import os
import re
from io import BytesIO
from pydantic import BaseModel

# à¸Šà¸µà¹‰ path à¹„à¸›à¸—à¸µà¹ˆ tesseract.exe à¸‚à¸­à¸‡à¸„à¸¸à¸“
pytesseract.pytesseract.tesseract_cmd = r"C:/Program Files/Tesseract-OCR/tesseract.exe"

load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")

app = FastAPI(title="AI Resume Analyzer API")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

client = Groq(api_key=API_KEY)

conversation_history = []
resume_uploaded = False
resume_cache = ""
interview_history = []  # ðŸ†• à¹€à¸à¹‡à¸šà¸›à¸£à¸°à¸§à¸±à¸•à¸´à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ


# -------------------------
# Extract Text (PDF/Images)
# -------------------------
def extract_text(uploaded_file) -> str:
    """Extract text from PDF or Image using OCR"""
    try:
        filename = uploaded_file.filename.lower()
        uploaded_file.file.seek(0)
        content = uploaded_file.file.read()

        if filename.endswith(".pdf"):
            # Convert PDF pages to images
            images = convert_from_bytes(content, poppler_path=r"C:/Program Files/poppler-25.07.0/Library/bin")
            text = ""
            for img in images:
                text += pytesseract.image_to_string(img, lang="eng+tha") + "\n"
            return text.strip()

        elif filename.endswith((".png", ".jpg", ".jpeg")):
            # OCR à¸ªà¸³à¸«à¸£à¸±à¸šà¸£à¸¹à¸›à¸ à¸²à¸ž
            image = Image.open(BytesIO(content))
            text = pytesseract.image_to_string(image, lang="eng+tha")
            return text.strip()

        else:
            return "âŒ Unsupported file format"

    except Exception as e:
        return f"âŒ Error extracting text: {str(e)}"


# -------------------------
# Extract scores %
# -------------------------
def extract_scores(text: str):
    pattern = r'(\d+(?:\.\d+)?)%'
    matches = re.findall(pattern, text)
    return [float(m) for m in matches]


# -------------------------
# Analyze Resume
# -------------------------
@app.post("/analyze")
async def analyze_resume(resume_file: UploadFile = File(...)):
    global resume_uploaded, resume_cache, conversation_history

    resume_text = extract_text(resume_file)
    resume_cache = resume_text
    resume_uploaded = True

    conversation_history.append({
        "role": "system",
        "content": f"à¸™à¸µà¹ˆà¸„à¸·à¸­à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰:\n{resume_cache[:1500]}"
    })

    # Prompt à¹à¸šà¸šà¹„à¸¡à¹ˆà¸¡à¸µ Job Description + ðŸ†• à¸šà¸­à¸à¸§à¹ˆà¸²à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸à¸±à¸šà¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸”à¹‰à¸§à¸¢
    prompt = f"""
à¸„à¸¸à¸“à¸„à¸·à¸­ AI Resume Analyzer à¸Šà¹ˆà¸§à¸¢à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰:

ðŸ“„ **à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£:**
{resume_text}

ðŸ“ **à¸„à¸³à¸ªà¸±à¹ˆà¸‡:**
- à¸Šà¸µà¹‰à¸ˆà¸¸à¸”à¹€à¸”à¹ˆà¸™à¹à¸¥à¸°à¸—à¸±à¸à¸©à¸°à¸—à¸µà¹ˆà¸ªà¸³à¸„à¸±à¸à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£
- à¸Šà¸µà¹‰à¸ˆà¸¸à¸”à¸—à¸µà¹ˆà¸„à¸§à¸£à¸›à¸£à¸±à¸šà¸›à¸£à¸¸à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¸¢à¸´à¹ˆà¸‡à¸‚à¸¶à¹‰à¸™
- à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™à¹à¸•à¹ˆà¸¥à¸°à¸ªà¹ˆà¸§à¸™ (à¸—à¸±à¸à¸©à¸°/à¸›à¸£à¸°à¸ªà¸šà¸à¸²à¸£à¸“à¹Œ/à¸„à¸§à¸²à¸¡à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œ) à¸žà¸£à¹‰à¸­à¸¡ Emoji à¸™à¸³à¸«à¸™à¹‰à¸²à¸›à¸£à¸°à¹‚à¸¢à¸„ à¸”à¸±à¸‡à¸™à¸µà¹‰:
  - âœ… à¸„à¸£à¸šà¸–à¹‰à¸§à¸™ à¸•à¸£à¸‡à¸•à¸²à¸¡à¸‚à¹‰à¸­à¸à¸³à¸«à¸™à¸”
  - âŒ à¹„à¸¡à¹ˆà¸„à¸£à¸šà¸«à¸£à¸·à¸­à¸‚à¸²à¸”à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸
  - âš ï¸ à¹„à¸¡à¹ˆà¸Šà¸±à¸”à¹€à¸ˆà¸™à¸«à¸£à¸·à¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­
- à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™ **à¸„à¸§à¸²à¸¡à¸ªà¸¡à¸šà¸¹à¸£à¸“à¹Œà¹‚à¸”à¸¢à¸£à¸§à¸¡** à¸‚à¸­à¸‡à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¹€à¸›à¹‡à¸™ %
- à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹ƒà¸Šà¹‰ bullet list à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™à¹à¸¥à¸°à¹à¸šà¹ˆà¸‡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸«à¸™à¸¶à¹ˆà¸‡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸«à¸™à¸¶à¹ˆà¸‡à¸šà¸£à¸£à¸—à¸±à¸”
- à¸—à¸¸à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¡à¸µ **à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸©à¸ªà¸±à¹‰à¸™à¹†** à¹„à¸”à¹‰ à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™ à¸«à¹‰à¸²à¸¡à¸¡à¸µà¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸ à¸²à¸©à¸²à¸­à¸·à¹ˆà¸™à¸­à¸­à¸à¸¡à¸²à¹€à¸”à¹‡à¸”à¸‚à¸²à¸”

â„¹ï¸ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸«à¸²à¸à¸–à¸¹à¸à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸£à¹ˆà¸§à¸¡à¸à¸±à¸šà¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ à¹ƒà¸«à¹‰à¸„à¸¸à¸“à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸šà¸£à¸´à¸šà¸—à¸ªà¸³à¸«à¸£à¸±à¸šà¸–à¸²à¸¡-à¸•à¸­à¸šà¹„à¸”à¹‰à¸”à¹‰à¸§à¸¢ 
    à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¸à¸²à¸£à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆ à¹à¸¥à¸°à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™à¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸”à¹‰à¸§à¸¢à¸à¸²à¸£à¸‚à¸­à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£ à¸«à¸²à¸à¹„à¸¡à¹ˆà¸¡à¸µà¹ƒà¸«à¹‰à¸‚à¹‰à¸²à¸¡à¹„à¸›à¹€à¸¥à¸¢
"""

    answer = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[
            {"role": "system", "content": "à¸„à¸¸à¸“à¸„à¸·à¸­ HR AI Analyzer"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=800,
    )

    report = answer.choices[0].message.content
    scores = extract_scores(report)
    avg_score = round(sum(scores) / len(scores), 2) if scores else None

    return JSONResponse({
        "resume_text": resume_text[:500],
        "report": report,
        "scores": scores,
        "average_score": avg_score
    })


# -------------------------
# Chat with AI (Emoji/Format)
# -------------------------
class ChatRequest(BaseModel):
    message: str


@app.post("/chat")
async def chat_with_ai(req: ChatRequest):
    global conversation_history, resume_uploaded, resume_cache

    user_message = req.message
    if resume_uploaded:
        user_content = f"{user_message}\n\n(ðŸ“„ à¸šà¸£à¸´à¸šà¸—à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸„à¸·à¸­ {resume_cache[:400]}...)"
    else:
        user_content = user_message

    conversation_history.append({"role": "user", "content": user_content})

    try:
        prompt = f"""
        - à¸„à¸¸à¸“à¸„à¸·à¸­ Job Assistant à¸‚à¸­à¸‡à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œ Job.Scraper TH à¹€à¸§à¹‡à¸šà¹„à¸‹à¸•à¹Œà¸—à¸µà¹ˆà¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸‡à¸²à¸™à¹ƒà¸™à¸›à¸£à¸°à¹€à¸—à¸¨à¹„à¸—à¸¢à¸ˆà¸²à¸à¹€à¸§à¹‡à¸š JobBKK JobTH JobThai [jobbkk.com, jobth.com, jobthai.com]
        - à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸•à¹ˆà¸­à¸‡à¸—à¸³à¸„à¸·à¸­à¸•à¸­à¸šà¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹à¸¥à¸°à¹ƒà¸Šà¹‰ Emoji à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢à¹€à¸žà¸·à¹ˆà¸­à¹€à¸™à¹‰à¸™à¸›à¸£à¸°à¹€à¸”à¹‡à¸™à¸ªà¸³à¸„à¸±à¸ à¹‚à¸”à¸¢à¹ƒà¸™à¸šà¸—à¸ªà¸™à¸—à¸™à¸²à¹€à¸£à¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™à¸œà¸¹à¹‰à¸«à¸à¸´à¸‡ à¸¥à¸‡à¸—à¹‰à¸²à¸¢à¸„à¸³à¸”à¹‰à¸§à¸¢(à¸„à¸°/à¸„à¹ˆà¸°)à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™
        - à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸§à¸±à¸ªà¸”à¸µà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ à¸«à¸²à¸à¹€à¸à¸µà¹ˆà¸¢à¸§à¸‚à¹‰à¸­à¸‡à¸à¸±à¸šà¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆ à¹ƒà¸«à¹‰à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¹‚à¸¢à¸‡à¸šà¸£à¸´à¸šà¸—à¸—à¸µà¹ˆà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹„à¸”à¹‰à¸­à¸±à¸›à¹‚à¸«à¸¥à¸”
        - à¸ˆà¸±à¸”à¸£à¸¹à¸›à¹à¸šà¸šà¹ƒà¸«à¹‰à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢ à¹ƒà¸Šà¹‰ bullet list à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™à¹à¸¥à¸°à¹à¸šà¹ˆà¸‡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸Šà¸±à¸”à¹€à¸ˆà¸™ à¸«à¸™à¸¶à¹ˆà¸‡à¸«à¸±à¸§à¸‚à¹‰à¸­à¸«à¸™à¸¶à¹ˆà¸‡à¸šà¸£à¸£à¸—à¸±à¸”
        - (à¸­à¸˜à¸´à¸šà¸²à¸¢à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¸„à¸¸à¸“à¸«à¹‰à¸²à¸¡à¹€à¸£à¸´à¹ˆà¸¡à¸—à¸³à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹ƒà¸”à¹†à¹€à¸”à¹‡à¸”à¸‚à¸²à¸”) à¸ªà¸²à¸¡à¸²à¸£à¸–à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸«à¸£à¸·à¸­à¸ˆà¸³à¸¥à¸­à¸‡ **à¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸‡à¸²à¸™** à¹„à¸”à¹‰ à¹‚à¸”à¸¢à¸à¸²à¸£à¸à¸”à¸›à¸¸à¹ˆà¸¡"à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ"à¸”à¹‰à¸²à¸™à¸‚à¸§à¸²à¸¥à¹ˆà¸²à¸‡à¹€à¸žà¸·à¹ˆà¸­à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹‚à¸«à¸¡à¸” à¸«à¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸–à¸²à¸¡à¹ƒà¸™à¸¥à¸±à¸à¸©à¸“à¸°à¸™à¸±à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ à¸•à¸±à¹‰à¸‡à¸„à¸³à¸–à¸²à¸¡à¹à¸šà¸š HR 
        - à¸—à¸¸à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¡à¸µ **à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸©à¸ªà¸±à¹‰à¸™à¹†** à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™ à¸«à¹‰à¸²à¸¡à¸¡à¸µà¸•à¸±à¸§à¸­à¸±à¸à¸©à¸£à¸ à¸²à¸©à¸²à¸­à¸·à¹ˆà¸™à¸­à¸­à¸à¸¡à¸²à¹€à¸”à¹‡à¸”à¸‚à¸²à¸”

à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸–à¸²à¸¡:
{user_message}

ðŸ“„ à¸šà¸£à¸´à¸šà¸—:
{"à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸¥à¹ˆà¸²à¸ªà¸¸à¸”: " + resume_cache[:400] + "..." if resume_uploaded else "à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆ"}
"""
        answer = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {"role": "system", "content": "à¸„à¸¸à¸“à¸„à¸·à¸­à¸œà¸¹à¹‰à¸Šà¹ˆà¸§à¸¢ AI à¹à¸Šà¸—à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸¡à¸´à¸•à¸£ à¹ƒà¸Šà¹‰à¸­à¸µà¹‚à¸¡à¸ˆà¸´à¹à¸¥à¸°à¸ˆà¸±à¸” format à¸­à¹ˆà¸²à¸™à¸‡à¹ˆà¸²à¸¢"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=500,
        )
        response_text = answer.choices[0].message.content
    except Exception as e:
        response_text = f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {str(e)}"

    conversation_history.append({"role": "assistant", "content": response_text})

    return JSONResponse({
        "reply": response_text,
        "history": conversation_history[-5:]
    })


@app.post("/interview")
async def interview_mode(req: ChatRequest):
    global conversation_history, resume_uploaded, resume_cache, interview_history

    user_message = req.message
    if resume_uploaded:
        user_content = f"{user_message}\n\n(ðŸ“„ à¸šà¸£à¸´à¸šà¸—à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡: à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸„à¸·à¸­ {resume_cache[:400]}...)"
    else:
        user_content = user_message

    conversation_history.append({"role": "user", "content": user_content})

    try:
        prompt = f"""
                - à¸„à¸¸à¸“à¸„à¸·à¸­ HR à¹€à¸žà¸¨à¸«à¸à¸´à¸‡à¸—à¸µà¹ˆà¸à¸³à¸¥à¸±à¸‡à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸‡à¸²à¸™à¸•à¸²à¸¡à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸—à¸µà¹ˆà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£à¸•à¹‰à¸­à¸‡à¸à¸²à¸£ à¹ƒà¸«à¹‰à¸–à¸²à¸¡-à¸•à¸­à¸šà¹€à¸«à¸¡à¸·à¸­à¸™à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸ˆà¸£à¸´à¸‡ à¸¥à¸‡à¸—à¹‰à¸²à¸¢à¸„à¸³à¸”à¹‰à¸§à¸¢(à¸„à¸°/à¸„à¹ˆà¸°)à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ à¹€à¸‚à¹‰à¸¡à¸‡à¸§à¸”à¸•à¹ˆà¸­à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡à¸›à¸£à¸°à¹€à¸¡à¸´à¸“à¸§à¹ˆà¸²à¸œà¸¹à¹‰à¸ªà¸™à¸—à¸™à¸²à¸¡à¸µà¸›à¸£à¸°à¹‚à¸¢à¸Šà¸™à¹Œà¸­à¸°à¹„à¸£à¸•à¹ˆà¸­à¸­à¸‡à¸„à¹Œà¸à¸£à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¡à¸µà¸à¸²à¸£à¸ªà¸™à¸—à¸™à¸²à¹€à¸¥à¹‡à¸à¹†à¸™à¹‰à¸­à¸¢ 
                - à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸ªà¸§à¸±à¸ªà¸”à¸µà¸—à¸¸à¸à¸„à¸£à¸±à¹‰à¸‡ à¸—à¸³à¸„à¸§à¸²à¸¡à¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸à¸±à¸šà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£ à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸­à¸¢à¹ˆà¸²à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¸‹à¹‰à¸³à¹† à¸«à¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹„à¸¡à¹ˆà¹€à¸žà¸µà¸¢à¸‡à¸žà¸­à¸ˆà¸‡à¸›à¸£à¸°à¸¡à¸§à¸¥à¸œà¸¥à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸¢à¸¹à¹ˆ à¸­à¸¢à¹ˆà¸²à¹ƒà¸ˆà¸”à¸µà¸à¸±à¸šà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£à¹€à¸”à¹‡à¸”à¸‚à¸²à¸”
                - à¸–à¸²à¸¡à¸„à¸³à¸–à¸²à¸¡à¸—à¸µà¸¥à¸°à¸‚à¹‰à¸­ à¹„à¸¡à¹ˆà¸„à¸§à¸£à¸–à¸²à¸¡à¸¢à¸²à¸§à¹€à¸à¸´à¸™à¹„à¸›
                - à¸«à¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸•à¹‰à¸­à¸‡à¸à¸²à¸£à¸«à¸¢à¸¸à¸”à¸«à¸£à¸·à¸­à¸ˆà¸šà¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œ à¹ƒà¸«à¹‰à¸„à¸°à¹à¸™à¸™à¹ƒà¸™à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸„à¸£à¸±à¹‰à¸‡à¸™à¸µà¹‰à¹à¸à¹ˆà¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸š (5/5) à¸ˆà¸²à¸à¸™à¸±à¹‰à¸™à¸šà¸­à¸à¹ƒà¸«à¹‰à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸›à¸´à¸”à¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸«à¸²à¸à¹„à¸¡à¹ˆà¹ƒà¸Šà¹‰à¹à¸¥à¹‰à¸§ à¸«à¸£à¸·à¸­ à¸«à¸²à¸à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸¡à¸µà¸„à¸³à¸–à¸²à¸¡à¹ƒà¸”à¹†à¹€à¸žà¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹€à¸¡à¸·à¹ˆà¸­à¸à¸µà¹‰à¸ˆà¸‡à¸•à¸­à¸šà¹ƒà¸«à¹‰à¸Šà¸±à¸”à¹€à¸ˆà¸™à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸–à¸µà¸–à¹‰à¸§à¸™ à¹à¸¥à¸° à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹ƒà¸«à¸¡à¹ˆà¸à¹‡à¹„à¸”à¹‰
                - à¸—à¸¸à¸à¸‚à¹‰à¸­à¸„à¸§à¸²à¸¡à¹ƒà¸«à¹‰à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢** à¹à¸¥à¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¡à¸µ **à¸ à¸²à¸©à¸²à¸­à¸±à¸‡à¸à¸¤à¸©à¸ªà¸±à¹‰à¸™à¹†à¹€à¸›à¹‡à¸™à¸Šà¸·à¹ˆà¸­à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸‡à¸²à¸™à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™à¸«à¸²à¸à¸ˆà¸³à¹€à¸›à¹‡à¸™** 
                - â„¹ï¸ à¸«à¸²à¸à¸–à¸¹à¸à¹ƒà¸Šà¹‰à¹ƒà¸™ endpoint à¸­à¸·à¹ˆà¸™ (à¹€à¸Šà¹ˆà¸™ chat/analyze) à¸„à¸¸à¸“à¸¢à¸±à¸‡à¸ªà¸²à¸¡à¸²à¸£à¸–à¸ˆà¸³à¸¥à¸­à¸‡à¹‚à¸«à¸¡à¸”à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¹„à¸”à¹‰à¹€à¸Šà¹ˆà¸™à¸à¸±à¸™

                à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰à¸•à¸­à¸š:
                {user_message}

                ðŸ“„ à¸šà¸£à¸´à¸šà¸—:
                {"à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸¥à¹ˆà¸²à¸ªà¸¸à¸”: " + resume_cache[:400] + "..." if resume_uploaded else "à¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆ"}
                """
        answer = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {"role": "system", "content": "à¸„à¸¸à¸“à¸„à¸·à¸­ HR à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸‡à¸²à¸™ à¹€à¸›à¹‰à¸²à¸«à¸¡à¸²à¸¢à¸„à¸·à¸­à¸à¸²à¸£à¸ªà¸±à¸¡à¸ à¸²à¸©à¸“à¹Œà¸„à¸¹à¹ˆà¸ªà¸™à¸—à¸™à¸²"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=500,
        )
        response_text = answer.choices[0].message.content
    except Exception as e:
        response_text = f"âŒ à¹€à¸à¸´à¸”à¸‚à¹‰à¸­à¸œà¸´à¸”à¸žà¸¥à¸²à¸”: {str(e)}"

    conversation_history.append({"role": "assistant", "content": response_text})
    interview_history.append({"question": user_message, "answer": response_text})  # ðŸ†• à¹€à¸à¹‡à¸š log

    return JSONResponse({
        "reply": response_text,
        "history": conversation_history[-5:]
    })


# -------------------------
# Interview Log (à¹ƒà¸«à¸¡à¹ˆ)
# -------------------------
@app.get("/interview_log")
async def get_interview_log():
    return JSONResponse({
        "interview_history": interview_history
    })

@app.post("/recommend/cv")
async def analyze_resume(resume_file: UploadFile = File(...)):

    resume_text = extract_text(resume_file)
    conversation_history.append({
        "role": "system",
        "content": f"à¸™à¸µà¹ˆà¸„à¸·à¸­à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸—à¸µà¹ˆà¸­à¸±à¸›à¹‚à¸«à¸¥à¸”à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¸‚à¸­à¸‡à¸œà¸¹à¹‰à¹ƒà¸Šà¹‰:\n{resume_cache[:1500]}"
    })

    prompt = f"""
à¸„à¸¸à¸“à¸„à¸·à¸­ AI Resume Analyzer à¸Šà¹ˆà¸§à¸¢à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸•à¹ˆà¸­à¹„à¸›à¸™à¸µà¹‰:

ðŸ“„ **à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£:**
{resume_text}

ðŸ“ **à¸„à¸³à¸ªà¸±à¹ˆà¸‡:**
- à¹à¸™à¸°à¸™à¸³à¸‡à¸²à¸™à¸—à¸µà¹ˆà¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸à¸±à¸šà¸œà¸¹à¹‰à¸ªà¸¡à¸±à¸„à¸£à¸•à¸²à¸¡à¹€à¸£à¸‹à¸¹à¹€à¸¡à¹ˆà¸—à¸µà¹ˆà¹ƒà¸«à¹‰à¸¡à¸² à¸ˆà¸³à¸™à¸§à¸™ 3 à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸‡à¸²à¸™
- à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰à¸£à¸¹à¸›à¹à¸šà¸šà¸”à¸±à¸‡à¸™à¸µà¹‰: Job1,Job2,Job3
- à¸žà¸¢à¸²à¸¢à¸²à¸¡à¸«à¸¥à¸µà¸à¹€à¸¥à¸µà¹ˆà¸¢à¸‡à¸„à¸³à¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰ Junior, Senior, Intern
- text à¸„à¸§à¸£à¸¡à¸µà¸„à¸§à¸²à¸¡à¸¢à¸²à¸§à¹„à¸¡à¹ˆà¹€à¸à¸´à¸™ 2 à¸„à¸³ 
"""

    answer = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[
            {"role": "system", "content": "à¸„à¸¸à¸“à¸„à¸·à¸­ HR AI Analyzer"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=1500,
    )

    response = answer.choices[0].message.content

    jobs = response.split(',')
    if len(jobs) >= 5:
        response = ','.join(jobs[:5])

    return JSONResponse({
        "reply": response,
        "jobs": jobs,
    })