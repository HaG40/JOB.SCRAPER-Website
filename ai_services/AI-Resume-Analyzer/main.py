# main.py
# uvicorn main:app --reload --port 5000

from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from groq import Groq
from dotenv import load_dotenv
from PIL import Image
from pdf2image import convert_from_bytes
import pytesseract
import os
import re
from io import BytesIO
from pydantic import BaseModel

# ‡∏ä‡∏µ‡πâ path ‡πÑ‡∏õ‡∏ó‡∏µ‡πà tesseract.exe ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
pytesseract.pytesseract.tesseract_cmd = r"C:/Program Files/Tesseract-OCR/tesseract.exe"

load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")

app = FastAPI(title="AI Resume Analyzer API")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

client = Groq(api_key=API_KEY)

conversation_history = []
resume_uploaded = False
resume_cache = ""
interview_history = []  # üÜï ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå


# -------------------------
# Extract Text (PDF/Images)
# -------------------------
def extract_text(uploaded_file) -> str:
    """Extract text from PDF or Image using OCR"""
    try:
        filename = uploaded_file.filename.lower()
        uploaded_file.file.seek(0)
        content = uploaded_file.file.read()

        if filename.endswith(".pdf"):
            # Convert PDF pages to images
            images = convert_from_bytes(content, poppler_path=r"C:/Program Files/poppler-25.07.0/Library/bin")
            text = ""
            for img in images:
                text += pytesseract.image_to_string(img, lang="eng+tha") + "\n"
            return text.strip()

        elif filename.endswith((".png", ".jpg", ".jpeg")):
            # OCR ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
            image = Image.open(BytesIO(content))
            text = pytesseract.image_to_string(image, lang="eng+tha")
            return text.strip()

        else:
            return "‚ùå Unsupported file format"

    except Exception as e:
        return f"‚ùå Error extracting text: {str(e)}"


# -------------------------
# Extract scores %
# -------------------------
def extract_scores(text: str):
    pattern = r'(\d+(?:\.\d+)?)%'
    matches = re.findall(pattern, text)
    return [float(m) for m in matches]


# -------------------------
# Analyze Resume
# -------------------------
@app.post("/analyze")
async def analyze_resume(resume_file: UploadFile = File(...)):
    global resume_uploaded, resume_cache, conversation_history

    resume_text = extract_text(resume_file)
    resume_cache = resume_text
    resume_uploaded = True

    conversation_history.append({
        "role": "system",
        "content": f"‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ:\n{resume_cache[:1500]}"
    })

    # Prompt ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ Job Description + üÜï ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏î‡πâ‡∏ß‡∏¢
    prompt = f"""
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ AI Resume Analyzer ‡∏ä‡πà‡∏ß‡∏¢‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

üìÑ **‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£:**
{resume_text}

üìù **‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á:**
- ‡∏ä‡∏µ‡πâ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏±‡∏Å‡∏©‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£
- ‡∏ä‡∏µ‡πâ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏¢‡∏¥‡πà‡∏á‡∏Ç‡∏∂‡πâ‡∏ô
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô (‡∏ó‡∏±‡∏Å‡∏©‡∏∞/‡∏õ‡∏£‡∏∞‡∏™‡∏ö‡∏Å‡∏≤‡∏£‡∏ì‡πå/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå) ‡∏û‡∏£‡πâ‡∏≠‡∏° Emoji ‡∏ô‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ ‡∏î‡∏±‡∏á‡∏ô‡∏µ‡πâ:
  - ‚úÖ ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô ‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î
  - ‚ùå ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
  - ‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
- ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô **‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°** ‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô %
- ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÉ‡∏ä‡πâ bullet list ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
- ‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ **‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏™‡∏±‡πâ‡∏ô‡πÜ** ‡πÑ‡∏î‡πâ ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î

‚ÑπÔ∏è ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡∏´‡∏≤‡∏Å‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ 
    ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà ‡πÅ‡∏•‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡πÄ‡∏•‡∏¢
"""

    answer = client.chat.completions.create(
        model="openai/gpt-oss-120b",
        messages=[
            {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ HR AI Analyzer"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.2,
        max_tokens=800,
    )

    report = answer.choices[0].message.content
    scores = extract_scores(report)
    avg_score = round(sum(scores) / len(scores), 2) if scores else None

    return JSONResponse({
        "resume_text": resume_text[:500],
        "report": report,
        "scores": scores,
        "average_score": avg_score
    })


# -------------------------
# Chat with AI (Emoji/Format)
# -------------------------
class ChatRequest(BaseModel):
    message: str


@app.post("/chat")
async def chat_with_ai(req: ChatRequest):
    global conversation_history, resume_uploaded, resume_cache

    user_message = req.message
    if resume_uploaded:
        user_content = f"{user_message}\n\n(üìÑ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠ {resume_cache[:400]}...)"
    else:
        user_content = user_message

    conversation_history.append({"role": "user", "content": user_content})

    try:
        prompt = f"""
        - ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ Job Assistant ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå Job.Scraper TH ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö JobBKK JobTH JobThai [jobbkk.com, jobth.com, jobthai.com]
        - ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πà‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏∑‡∏≠‡∏ï‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ Emoji ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ô‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏î‡πá‡∏ô‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÇ‡∏î‡∏¢‡πÉ‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á ‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢(‡∏Ñ‡∏∞/‡∏Ñ‡πà‡∏∞)‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà ‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î
        - ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢ ‡πÉ‡∏ä‡πâ bullet list ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡πà‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î
        - (‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡∏Ñ‡∏∏‡∏ì‡∏´‡πâ‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡πÉ‡∏î‡πÜ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î) ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏≥‡∏•‡∏≠‡∏á **‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô** ‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°"‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå"‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏•‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÇ‡∏´‡∏°‡∏î ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏ö‡∏ö HR 
        - ‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ **‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏™‡∏±‡πâ‡∏ô‡πÜ** ‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡∏´‡πâ‡∏≤‡∏°‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î

‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°:
{user_message}

üìÑ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:
{"‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: " + resume_cache[:400] + "..." if resume_uploaded else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà"}
"""
        answer = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡πÅ‡∏ä‡∏ó‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÉ‡∏ä‡πâ‡∏≠‡∏µ‡πÇ‡∏°‡∏à‡∏¥‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î format ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.4,
            max_tokens=500,
        )
        response_text = answer.choices[0].message.content
    except Exception as e:
        response_text = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

    conversation_history.append({"role": "assistant", "content": response_text})

    return JSONResponse({
        "reply": response_text,
        "history": conversation_history[-5:]
    })


@app.post("/interview")
async def interview_mode(req: ChatRequest):
    global conversation_history, resume_uploaded, resume_cache, interview_history

    user_message = req.message
    if resume_uploaded:
        user_content = f"{user_message}\n\n(üìÑ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏Ñ‡∏∑‡∏≠ {resume_cache[:400]}...)"
    else:
        user_content = user_message

    conversation_history.append({"role": "user", "content": user_content})

    try:
        prompt = f"""
                - ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ HR ‡πÄ‡∏û‡∏®‡∏´‡∏ç‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô‡∏ï‡∏≤‡∏°‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏à‡∏£‡∏¥‡∏á ‡∏•‡∏á‡∏ó‡πâ‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢(‡∏Ñ‡∏∞/‡∏Ñ‡πà‡∏∞)‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ì‡∏ß‡πà‡∏≤‡∏ú‡∏π‡πâ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡πà‡∏≠‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡πÄ‡∏•‡πá‡∏Å‡πÜ‡∏ô‡πâ‡∏≠‡∏¢ 
                - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡πÜ ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏à‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà ‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏à‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
                - ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠ ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ñ‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
                - ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏¢‡∏∏‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ô‡∏µ‡πâ‡πÅ‡∏Å‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (5/5) ‡∏à‡∏≤‡∏Å‡∏ô‡∏±‡πâ‡∏ô‡∏ö‡∏≠‡∏Å‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡∏´‡∏£‡∏∑‡∏≠ ‡∏´‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏î‡πÜ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏Å‡∏µ‡πâ‡∏à‡∏á‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ñ‡∏µ‡∏ñ‡πâ‡∏ß‡∏ô ‡πÅ‡∏•‡∏∞ ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡πÉ‡∏´‡∏°‡πà‡∏Å‡πá‡πÑ‡∏î‡πâ
                - ‡∏ó‡∏∏‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô **‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢** ‡πÅ‡∏•‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏°‡∏µ **‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡∏™‡∏±‡πâ‡∏ô‡πÜ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏á‡∏≤‡∏ô‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô** 
                - ‚ÑπÔ∏è ‡∏´‡∏≤‡∏Å‡∏ñ‡∏π‡∏Å‡πÉ‡∏ä‡πâ‡πÉ‡∏ô endpoint ‡∏≠‡∏∑‡πà‡∏ô (‡πÄ‡∏ä‡πà‡∏ô chat/analyze) ‡∏Ñ‡∏∏‡∏ì‡∏¢‡∏±‡∏á‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô

                ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ö:
                {user_message}

                üìÑ ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:
                {"‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î: " + resume_cache[:400] + "..." if resume_uploaded else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏£‡∏ã‡∏π‡πÄ‡∏°‡πà"}
                """
        answer = client.chat.completions.create(
            model="openai/gpt-oss-120b",
            messages=[
                {"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ HR ‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏á‡∏≤‡∏ô ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏™‡∏±‡∏°‡∏†‡∏≤‡∏©‡∏ì‡πå‡∏Ñ‡∏π‡πà‡∏™‡∏ô‡∏ó‡∏ô‡∏≤"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=500,
        )
        response_text = answer.choices[0].message.content
    except Exception as e:
        response_text = f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}"

    conversation_history.append({"role": "assistant", "content": response_text})
    interview_history.append({"question": user_message, "answer": response_text})  # üÜï ‡πÄ‡∏Å‡πá‡∏ö log

    return JSONResponse({
        "reply": response_text,
        "history": conversation_history[-5:]
    })


# -------------------------
# Interview Log (‡πÉ‡∏´‡∏°‡πà)
# -------------------------
@app.get("/interview_log")
async def get_interview_log():
    return JSONResponse({
        "interview_history": interview_history
    })
